{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "np.set_printoptions(precision=4, linewidth=150)\n",
    "style = plt.style.library['bmh']\n",
    "style_colors = [ c['color'] for c in style['axes.prop_cycle'] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 신경망 학습\n",
    "\n",
    "* * *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ <spen style=\"color: gold;\">**학습**</spen> == 훈련 데이터로부터 가중치 매개변수의 최적값을 자동으로 획득하는 것\n",
    "+ <spen style=\"color: gold;\">**손실함수**</spen> == 신경망이 학습할 수 있도록 해주는 <spen style=\"color: rosybrown;\">**지표**</spen>  \n",
    "<spen style=\"color: palevioletred;\">**학습목표 : 손실 함수의 결과값을 가장 작게 만드는 가중치 매개변수를 찾는것**</spen>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 데이터에서 학습한다 !\n",
    "+ 신경망의 특징\n",
    "    + 데이터를 보고 학습할 수 있다 == 가중치 매개변수의 값을 데이터를 보고 자동으로 결정한다\n",
    "\n",
    "+ 퍼셉트론도 직선으로 분리할 수 있는 ( 선형 분리 가능 ) 문제라면 데이터로부터 자동으로 학습할 수 있음\n",
    "    + 선형 분리 가능 문제는 유한 번의 학습을 통해 풀 수 있다는 사실이 <spen style=\"color: rosybrown;\">**퍼셉트론 수렴 정리 ( perceptron convergence theorem )**</spen> 로 증명됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <br><br><span style=\"color: mediumaquamarine;\">**데이터 주도 학습**</spen>\n",
    "+ <spen style=\"color: gold;\">**기계학습**</spen> == 데이터에서 답을 찾고 데이터에서 패턴을 발견하고 데이터로 이야기를 만드는것\n",
    "+ 기계학습의 중심에 <spen style=\"color: rosybrown;\">**데이터**</spen>가 존재 ( 데이터가 없으면 아무것도 시작되지 않음 )\n",
    "    + 데이터가 이끄는 접근 방식 덕에 사람 중심 접근에서 벗어날 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 기계학습에서는 사람의 개입을 최소화하고 수집한 데이터로부터 패턴을 찾으려고 시도함\n",
    "+ 신경망 && 딥러닝은 기존 기계학습에서 사용하던 방법보다 사람의 개입을 더욱 배제할 수 있게 해주는 중요한 특성을 지님"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "손글씨 숫자 '5'의 예 : 사람마다 자신만의 필체가 있다.  \n",
    "<img src=\"../img/mnist_5.png\" width='600'>\n",
    "\n",
    "+ '5'를 인식하는 알고리즘을 밑바닥부터 '설계하는' 대신, 주어진 데이터를 잘 활용해서 해결\n",
    "+ <spen style=\"color: palevioletred;\">**이미지에서 특징을 추출하고 그 특징의 패턴을 기계학습 기술로 학습하는 방법**</spen>\n",
    "    + <spen style=\"color: gold;\">**특징 ( feature )**</spen> == 입력 데이터 ( 입력 이미지 ) 에서 본질적인 데이터 ( 중요한 데이터 ) 를 정확하게 추출할 수 있도록 설계된 변환기\n",
    "        + 벡터로 기술\n",
    "        + 컴퓨터 비전 분야에서는 SIFT, SURF, HOG 등의 특징을 많이 사용\n",
    "        + <spen style=\"color: palevioletred;\">**이미지 데이터를 벡터로 변환하고, 변환된 벡터를 가지고 지도 학습 방식의 대표 분류 기법인 SVM, KNN 등으로 학습할 수 있다.**</spen>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 기계학습에서는 모아진 데이터로부터 규칙을 찾아내는 역할을 '기계'가 담당함  \n",
    "\n",
    "🚨 이미지를 벡터로 변환할 때 사용하는 특징은 여전히 '사람'이 설계하는 것이다. 🚨  \n",
    "+ 문제에 적합한 특징을 쓰지 않으면 ( || 특징을 설계하지 않으면 ) 좀처럼 좋은 결과를 얻을 수 없음\n",
    "\n",
    "\n",
    "<spen style=\"color: palevioletred;\">**특징과 기계학습을 활용한 접근에도 문제에 따라서는 '사람'이 적절한 특징을 생각해내야 한다.**</spen>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "규칙을 '사람'이 만드는 방식에서 '기계'가 데이터로부터 배우는 방식으로의 패러다임 전환 : 회색 블록은 사람이 개입하지 않음을 뜻한다.\n",
    "\n",
    "<img src=\"../img/machine_learning.png\" width='600'>\n",
    "\n",
    "+ 신경망은 이미지를 '있는 그대로' 학습한다.\n",
    "    + 신경망 == 딥러닝 == <spen style=\"color: gold;\">**종단간 기계학습 ( end-to-end machine learning )**</spen>\n",
    "        + 종단간 == 처음부터 끝까지\n",
    "        + 데이터 ( 입력 ) 에서 목표한 결과 ( 출력 ) 를 사람의 개입 없이 얻는다는 뜻\n",
    "+ 신경망의 이점 == 모든 문제를 같은 맥락에서 풀 수 있다.\n",
    "    + 세부사항과 관계없이 신경망은 주어진 데이터를 온전히 학습하고, 주어진 문제의 패턴을 발견하려고 시도함\n",
    "    + <spen style=\"color: palevioletred;\">**신경망은 모든 문제를 주어진 데이터 그대로 입력 데이터로 활용해 'end-to-end'로 학습할 수 있음**</spen>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <br><br><span style=\"color: mediumaquamarine;\">**훈련 데이터와 시험 데이터**</spen>\n",
    "<spen style=\"color: palevioletred;\">**기계학습에서 데이터를 취급할 때 주의할 점**</spen>  \n",
    "+ 기계학습 문제는 데이터를 <spen style=\"color: gold;\">**훈련 데이터 ( training data )**</spen> 와 <spen style=\"color: gold;\">**시험 데이터 ( test data )**</spen> 로 나눠 학습과 실험을 수행하는 것이 일반적\n",
    "    1. 훈련 데이터만 사용하여 학습하면서 최적의 매개변수를 찾음\n",
    "    2. 시험 데이터를 사용하여 앞서 훈련한 모델의 실력 평가</br></br>  \n",
    "\n",
    "훈련 데이터와 시험 데이터를 왜 나눠야 하는가 ❔  \n",
    "+ 기계학습은 원하는 것은 범용적으로 사용할 수 있는 모델이기 때문\n",
    "+ <spen style=\"color: rosybrown;\">**범용능력**</spen>을 제대로 평가하기 위해 훈련 데이터와 <spen style=\"color: rosybrown;\">**시험 데이터**</spen>를 분리함\n",
    "    + <spen style=\"color: gold;\">**범용 능력**</spen> == 아직 보지 못한 데이터 ( 훈련 데이터에 포함되지 않는 데이터 ) 로도 문제를 올바르게 풀어내는 능력\n",
    "    \n",
    "<spen style=\"color: palevioletred;\">**범용 능력을 획득하는 것이 기계학습의 최종 목표이다.**</spen>  \n",
    "+ 데이터셋 하나로만 매개변수의 학습과 평가를 수행하면 올바른 평가가 될 수 없음\n",
    "+ 수중의 데이터셋은 제대로 맞히더라도 다른 데이터셋에는 엉망인 일도 벌어짐\n",
    "+ <spen style=\"color: gold;\">**오버피팅 ( overfitting )**</spen> == 한 데이터셋에만 지나치게 최적화된 상태\n",
    "+ <spen style=\"color: palevioletred;\">**기계학습의 중요한 과제 == 오버피팅 피하기**</spen>\n",
    "\n",
    "\n",
    "\n",
    "ex ) 손글씨 숫자 인식의 최종 결과 == 엽서에서 우편 번호를 자동으로 판독하는 시스템\n",
    "<pre>    + '누군가' ? '임의의 사람의 임의의 글자' : '특정인의 특정 글자' 가 쓴 글자를 인식하는 능력이 높지 않으면 안됨</pre>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "school",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
